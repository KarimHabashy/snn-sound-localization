## Introduction 

We chose sound localisation using interaural time differences as the topic of the original [Cosyne tutorial that kicked off this project](https://neural-reckoning.github.io/cosyne-tutorial-2022/) {cite:p}`10.5281/zenodo.7044500`. The reasoning was that the tutorial was about spiking neural networks, and their unique distinguishing feature is the way that time is processed, something that is particularly important in the sound localisation circuit.

We are able to localise sound by detecting location- or direction-specific cues in the signals that arrive at our ears. One of the most important source of cues (although not the only one) come from differences in the signal between two ears, including both timing and level differences (interaural timing difference or ITD, and interaural level difference or ILD). Humans are able to detect arrival time differences in some cases as small as 20 $\mu$s.

The classic model of ITD sensitivity is the delay line model of {cite:t}`Jeffress1948` in which an array of binaural coincidence detector neurons receive inputs from the two ears with different delays. When the neural delays exactly match the acoustic delays induced by the sound location, the neuron is most active, and therefore the identity of the most active neuron can tell you the direction of the sound. This model was shown to be inefficient with respect to neural noise by {cite:t}`McAlpine2003`, who proposed an alternative model based on average firing rates of the two binaural hemispheres. This model was shown to be optimally robust to neural noise. {cite:t}`goodman_decoding_2013` showed that this model performed too poorly to account for behavioural data, especially in situations where sounds had complex and unknown spectral properties, or in the presence of background noise, and proposed an alternative based on a perceptron-like neural network that was both robust to neural noise and performed well across a range of conditions.

The starting point of this project was to ask: what solutions would you find if you directly optimised a spiking neural network to localise sounds? How would those solutions depend on the available neural mechanisms and statistics of the sound? Could we understand the solutions found in a simple way? What properties would the solution have in terms of robustness to noise, generalisation, and so forth? Could the solutions found by optimisation throw light on features found in the auditory systems of different animals? 

## A simple spiking neural network model

We started with a simple, trainable spiking neural network model (described in more detail in [](#basic-methods)) carrying out a highly abstracted sound localisation task. The task is to estimate the ITD of a pure tone (sine wave) at a fixed frequency. This is equivalent to estimating the interaural phase difference (IPD) since the ITD is ambiguous for a sine wave. The model consists of a layer of spiking input neurons, a single hidden layer of spiking neurons, and a non-spiking output layer of neurons. There are two subpopulations of input neurons corresponding to the two ears, with signals to one ear delayed with respect to the other. Each neuron within a subpopulation has a different phase delay. These neurons are all-to-all connected to the layer on hidden neurons with a trainable weight matrix. In this way, during training the model is free to *select* the neurons with the appropriate phase delays to get the desired properties for the hidden layer neurons. This lets the model learn to make use of delays without having to directly implement trainable delays, as this is a challenging problem (although note that a number of groups did manage to make this work, discussed below in [](#overview-delays)).

Input neurons fired spikes according to a Poisson process with a time-varying rate determined by the input stimulus. Hidden layer neurons were leaky integrate-and-fire neurons. Output neurons were leaky neurons with no spiking. Each output neuron is associated to a particular IPD, and the estimated IPD of the model is the identity of the most active output neuron.

Using this setup, we successfully trained SNNs on this task, and found that accuracy increased as we reduced the membrane time constant of the units in the hidden layer ([](../research/Optimizing-Membrane-Time-Constant.ipynb)). This initially suggested that coincidence detection played an important role. However, further analysis in [](../../research/time-constant-solutions.ipynb) (described in more detail in [](#basic-model)) showed that in fact, the network was not using a coincidence detection strategy, or indeed a spike timing strategy. Rather, it appears to be using an approach similar to the equalisation-cancellation theory {cite:p}`durlach_equalization_1963;culling_equalization-cancellation_2020` of subtracting various pairs of signals to find the point where they approximately cancel. Careful analysis of the trained model showed that it could be extremely well approximated by a 6-parameter model that is quite easy to describe, but does not obviously correspond to any known features of the auditory system.

Building on this base model, we explored two main questions: how changing the neuron model alters the network's behaviour and how the phase delays (within each ear) can be learned.
    
## Alternative neuron models  

### Dale's principle 

In biological networks most neurons release the same set of transmitters from all of their synapses, and so can be broadly be considered to be excitatory or inhibitory to their post-synaptic partners; a phenomenon known as Dale's principle. In contrast, most neural network models, including our base model, allow single units to have both positive and negative output weights.

To test the impact of restricting units to being either excitatory or inhibitory, we trained our base model across a range of inhibitory:excitatory unit ratios, and tested it's performance on unseen, test data ([](../research/Dales_law.ipynb)). We found that networks which balanced excitation and inhibition performed significantly better than both inhibition-only networks - which perform at chance level as no spikes propagate from the hidden to output layer, and excitation-only networks - which were roughly 30% less accurate than balanced networks.

To understand where in the network inhibition is required, we then trained a second set of networks in which we forced either the input or hidden units to be all excitatory, and set the remaining units to be half inhibitory and half excitatory. Networks with all excitatory hidden units performed as well as networks with balanced units, while networks with purely excitatory inputs performed significantly worse, demonstrating a role for inhibition in the input-hidden connections / delay lines.

Inhibition therefore plays an important role in this model, in line with experimental data that shows that blocking inhibition eliminates ITD-sensitivity in the medial superior olive [@Brand2002;@Pecka2008].

### Filter-and-fire

Unlike most point neuron models, in which pairs are connected by a single weight, many biological neurons make multiple contacts with their post-synaptic partners at different points along their dendritic tree. These contacts evoke post-synaptic potentials (PSPs) with distinct temporal dynamics, depending on their distance from the soma, with distal/proximal contacts inducing prolonged/brief PSPs. These features are captured by the filter-and-fire neuron model (F&F) [@beniaguev_dendro_plexing_2024], in which units make multiple contacts with their partners and each input is convolved with a distance-from-soma dependent synaptic filter. While networks of F&F units outperform networks of LIF units on a temporal version of MNIST, we hypothesised that this difference would be magnified in our sound localisation task, given it's natural temporal structure. We found that while training performance was increased using the F&F model, test performance was much worse, suggesting overfitting.

(overview-delays)=
## Learning delays 
Many studies which incorporate axonal and/or dendritic delays include them as non-learnable parameters like our base model. Here we explore how these phase delays can be learned through two approaches.

The first method was to use the method of dilated convolutions with learnable spacings (DCLS) [@hassani2023dilated;@hammouamri2024learning]. This method uses a 1D convolution through time to simulate delays between consecutive layers. The kernels include a single non-zero weight per-synapse, which corresponds to the desired delay. This method can learn both weights and delays.

The second method was by introducing a differentiable delay layer (DDL). This method uses a combination of translation and interpolation, where the interpolation allows the delays to be differentiable even though time steps are discrete. This can be placed between any two layers in a spiking neural network, and also allows weights and delays to be trained separately. This work is described in more detail in [](#delay-section).

Both methods were able to perform well and eliminate the artificial phase delays introduced in the basic model.

## Detailed inhibition-based model

Finally, we developed a more detailed model in which we used over 170,000 units, with conductance-based synapses, to approximate the structure of the mammalian brainstem circuit (see more details in [](#inhib-model)).
In short, input spectrograms representing sounds at azimuth angles from -90° to +90° were converted into spikes, then passed forward to populations representing the globular and spherical bushy cells, and subsequently the lateral and medial superior olivary nuclei, from which we readout sound source angle predictions. Note that, unlike the work with our simple model, we used no learnable parameters in this model, and instead based parameters on neurophysiological data. For example, the MSO units had excitatory inputs from both the ipsi and contralateral SBCs and dominant inhibition from contralateral GBCs.

The model was able to produce realisic tuning curves for lateral and medial superior olive (LSO, MSO) neurons). Turning off inhibition shifted ITD sensitivity to the midline, as in [@Brand2002;@Pecka2008].